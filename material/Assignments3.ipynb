{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigments 3.1\n",
    "\n",
    "This first part of the assignment requires to implement yourself basic cross-validation strategies.\n",
    "\n",
    "__ Exercise 1.__ Define a 10-fold classification strategy to test the accuracy of a Linear Discriminant Analysis (LDA) classifier for the data created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 100, n_features=2, n_redundant=0, n_informative=2, \\\n",
    "                           random_state=0, n_clusters_per_class=1, weights = [0.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.__ Use the previous 10-fold cross-validation to plot and compute the average area under the curve of the LDA classifier. You can use the built in method __ predict_proba(X) __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Exercise 3.__ Define the appropriate cross-validation strategy and measurement of the area under the curve for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 200, n_features=5, n_redundant=0, n_informative=3, \\\n",
    "                           random_state=0, n_clusters_per_class=1, weights = [0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigments 3.2\n",
    "\n",
    "__Exercise 1.__ During lesson we discussed the problem of _selection bias_ in cross-validation. \n",
    "This problem is nicely investigated in the paper _On the Dangers of Cross-Validation. An Experimental Evaluation_, accessible here:\n",
    "\n",
    "http://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf\n",
    "\n",
    "\n",
    "Read  \n",
    "- Section 1 (Introduction), \n",
    "- Section 4 (Experiments on Synthetic Data), \n",
    "- Section 7 (Discussion)\n",
    "\n",
    "And write a short summary (~half a page) about these three sections (results and take home message).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.__ Try to replicate the problem of selection bias on some synthetic data, as seen during lesson. \n",
    "You can follow this strategy:\n",
    "\n",
    "1- Create some random data X with __N samples __ = 50 and __d dimensions__ = 200. Therefore $dim(X) = (50,200)$.\n",
    "\n",
    "2- Create random binary labels target y taking values  0 and 1 with p = 0.5. Therefore $dim(y) = 50$.\n",
    "\n",
    "3- Using this data, cross-validate a classification algorithm with different tuning of the parameters. \n",
    "You can use a Multi-layer Perceptron classifier, with different values for the range of the hidden value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42499999999999999, 0.69999999999999996, 0.51666666666666672, 0.58333333333333337, 0.57499999999999996, 0.58333333333333326, 0.56666666666666665, 0.60833333333333339, 0.53333333333333333, 0.54166666666666663, 0.56666666666666665]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(10)\n",
    "\n",
    "N_sample = 50\n",
    "d = 200\n",
    "\n",
    "X = np.random.randn(N_sample*d).reshape(N_sample,d)\n",
    "y = np.random.randint(0,2,N_sample)\n",
    "\n",
    "range_hidden_layer = [2,5,10,20,50,100,150,200,350,500,1000]\n",
    "\n",
    "acc = []\n",
    "\n",
    "for i in range_hidden_layer:\n",
    "    model = MLPClassifier(hidden_layer_sizes = (i,))\n",
    "    single_fold_acc = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        model.fit(X[train],y[train])\n",
    "        single_fold_acc.append(model.score(X[test],y[test]))\n",
    "    acc.append(np.mean(single_fold_acc))    \n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Which model gives the best predictive accuracy?\n",
    "\n",
    "5- What can we conclude from this experiment? Explain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,train].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
