{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayesian reasoning\n",
    "\n",
    "Suppose you have fever and look on internet about the possible causes. You then find that 20% of times fever can come with a cold, while 75% of times it comes with appendicitis. What would be your reaction? \n",
    "In practical terms, we are saying that the probabilities of our outcomes are\n",
    "\n",
    "$$ p(fever | cold) = 0.2, $$\n",
    "\n",
    "and that \n",
    "\n",
    "$$ p(fever | appendicitis) = 0.75. $$\n",
    "\n",
    "\n",
    "I guess that this would sound however a bit odd according to your common sense. This common sense is actually your knowledge about the world, that tells you that appendicits is not such a common event, at least as compared to a cold. You can see that there is a great difference between the probability of symtpoms given a disease (what you read on internet), and the probability of the disease given the symptoms (what you want to know).\n",
    "\n",
    "This difference in probabilities can be formalized within the framework of Bayesian reasoning. \n",
    "\n",
    "In particular, what we called common sense, or knowledge about the world, is what we call _prior_. The process we are making with our reasoning, is to weight the possible outcomes by the respective prior information. For example, supposing that we are in winter, a cold would not be such a rare event, and it may affect 80% of the population. On the conntrary, appendicitis is much rare, and affects 2% of the population.\n",
    "In other words, we are saying that:\n",
    "\n",
    "$$p(cold) = 0.8,$$\n",
    "\n",
    "and \n",
    "\n",
    "$$p(appendicitis) = 0.02.$$\n",
    "\n",
    "\n",
    "If we use these probabilities to weight our outcomes, we would obtain that the probability of having a cold would be realated to the product $p(fever | cold) * p(cold)$, while the probability of having appendicitis would be related to $p(fever | appendicitis) p(appendicitis)$. In numbers we will get\n",
    "\n",
    "$$ p(fever | cold)  p(cold) = 0.2*0.8 = 0.16,$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ p(fever | appendicitis)  p(appendicitis) = 0.75*0.02 = 0.015.$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(fever | cold) * p(cold) = 0.16\n",
      "p(fever | appendicitis) * p(appendicitis) = 0.015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "p_fever_given_cold = 0.2\n",
    "p_fever_given_appendicits = 0.75\n",
    "\n",
    "p_cold = 0.8\n",
    "p_appendicitis = 0.02\n",
    "\n",
    "print('p(fever | cold) * p(cold) = {}'.format(p_fever_given_cold*p_cold))\n",
    "print('p(fever | appendicitis) * p(appendicitis) = {}'.format(p_fever_given_appendicits*p_appendicitis))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we would like the events to sum up to one, in order to express probabilities. The natural way for obtaining this is by dividing the products by their sum. We then obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized probabilities:\n",
      "p(fever | cold) * p(cold) = 0.914285714286\n",
      "p(fever | appendicitis) * p(appendicitis) = 0.0857142857143\n"
     ]
    }
   ],
   "source": [
    "denominator = p_fever_given_cold*p_cold + p_fever_given_appendicits*p_appendicitis\n",
    "\n",
    "print('Normalized probabilities:')\n",
    "print('p(fever | cold) * p(cold) = {}'.format(p_fever_given_cold*p_cold/denominator))\n",
    "print('p(fever | appendicitis) * p(appendicitis) = {}'.format(p_fever_given_appendicits*p_appendicitis/denominator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of notation\n",
    "\n",
    "We now start rephrasing the problem with some formalism. Let's call the event _having fever_ as the data $X$. Let's also denote the possible causes, cold and appendicitis, as respectively models $M_1$ and $M_2$. So, by rewriting what we have seen so far, we get:\n",
    "\n",
    "$$ p(X|M_1) = 0.2, $$\n",
    "\n",
    "$$ p(X|M_2) = 0.75, $$\n",
    "\n",
    "$$ p(M_1) = 0.8, $$\n",
    "\n",
    "$$ p(M_2) = 0.02. $$\n",
    "\n",
    "The term $p(X|M)$ is called _data likelihood_. It expresses the probability of observing the data $X$ (fever) when knowing that the model $M$ (cold) is true. It is therefore the link between the observations and the underlying model. The term $p(M)$ is instead the _prior_. It does not depend on the data, and quantifies our belief that the model $M$ is true. When making inference (which disease we have) we are interested in computing the quantity $p(M|X)$. This quantity is called _posterior_, as it expresses the probability of the model _a posteriori_, i.e. after that the data is observed. The Bayes' theorem links these elements together through the famous formula:\n",
    "\n",
    "\n",
    "$$ p(M|X) = \\frac{p(X|M)p(M)}{p(X)}. $$\n",
    "\n",
    "To compute the posterior via the Bayes formula we miss the denominator $p(X)$. This quantity acts as a normalizing term since that, as we have seen before, we need to obtain a probability that integrates to one. To practically compute this term, we can use the law of total probability:\n",
    "\n",
    "$$ p(X) = \\int p(X|M)p(M) dM, $$\n",
    "\n",
    "which, states that the probability of an event is the sum (potentially infinite) of the probability of the event conditioned on any possible model, multiplied by the probability of the model. In our case, if we assume that all the possibilities reduce to the events _cold_ and _appendicitis_, we can simply write:\n",
    "\n",
    "$$ p(X) = p(X|M_1)p(M1) +  p(X|M_2)p(M2). $$\n",
    "\n",
    "Back to our simple example, we note that this term corresponds with the normalizing factor that we used before. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries for Bayesian model selection\n",
    "\n",
    "We suppose that, for a given data $X$, we would like to compare 2 competing models $M_1$ and $M_2$.\n",
    "In a Bayesian setting, we would like to quantify the probability of a given model given the observations, which is expressed as :\n",
    "\n",
    "$$ p(M|X).$$\n",
    "\n",
    "This quantity can be reformulated thanks to the Bayes rule:\n",
    "\n",
    "$$ p(M|X) = \\frac{p(X|M)p(M)}{p(X)}. $$\n",
    "\n",
    "In this formula, the term linking the data to the model is the probability $p(X|M)$. Therefore, two different models can be compared on the basis of the discrepancy between their associated probabilities. This discrepancy is called __Bayes factor__, and is quantified as the ratio:\n",
    "\n",
    "\n",
    "$$ B = \\frac{p(X|M_1)}{p(X|M_2)},$$\n",
    "\n",
    "which is equivalent to \n",
    "\n",
    "$$ B = \\frac{p(M_1|X)}{p(M_2|X)} \\frac{p(M_2)}{p(M_1)}. $$\n",
    "\n",
    "If we assume that the models $M_1$ and $M_2$ have the same probability a priori, $p(M_2) = p(M_1)$, the Bayes factor is the ratio between the models' posteriors: \n",
    "\n",
    "$$ B = \\frac{p(M_1|X)}{p(M_2|X)}$$.\n",
    "\n",
    "\n",
    "This ratio is also called _posterior odds_, and is defined more generally as:\n",
    "\n",
    "$$ R = \\frac{p(M_1|X)}{p(M_2|X)}  = \\frac{p(X|M_1)p(M_1)}{p(X|M_2)p(M_2)}.$$\n",
    "\n",
    "The posterior odds are therefore the product between the Bayes factor and the ratio between the prior, called _prior odds_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prior and posterior for cold are: 0.8 and 0.914285714286\n",
      "The prior and posterior for appendicitis are: 0.02 and 0.0857142857143\n",
      "The Bayes factor is: 0.266666666667\n",
      "The prior odds are: 40.0\n",
      "The posterior odds are: 10.6666666667\n"
     ]
    }
   ],
   "source": [
    "likelihood_cold = p_fever_given_cold\n",
    "prior_cold = p_cold\n",
    "\n",
    "likelihood_appendicitis = p_fever_given_appendicits\n",
    "prior_appendicitis = p_appendicitis\n",
    "\n",
    "p_fever = p_fever_given_cold*p_cold + p_fever_given_appendicits*p_appendicitis\n",
    "\n",
    "posterior_cold = likelihood_cold * prior_cold / p_fever\n",
    "posterior_appendicitis = likelihood_appendicitis * prior_appendicitis / p_fever\n",
    "\n",
    "bayes_factor = posterior_cold * prior_appendicitis/ (posterior_appendicitis * prior_cold)\n",
    "prior_odds = prior_cold/prior_appendicitis\n",
    "posterior_odds = posterior_cold/posterior_appendicitis\n",
    "\n",
    "\n",
    "print('The prior and posterior for cold are: {} and {}'.format(prior_cold,posterior_cold))\n",
    "print('The prior and posterior for appendicitis are: {} and {}'.format(prior_appendicitis, posterior_appendicitis))\n",
    "print('The Bayes factor is: ' + str(bayes_factor))\n",
    "print('The prior odds are: ' + str(prior_odds))\n",
    "print('The posterior odds are: ' + str(posterior_odds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalizing the model evidence\n",
    "\n",
    "Beyond the toy problem of before, the Bayes factor completely depends on the _model evidence_ $p(X|M)$. We note that a model is identified by its own parameters $\\boldsymbol{\\theta} = \\{ \\theta_1, \\theta_2, \\ldots, \\theta_k \\}$. Therefore, the probability associated to the model depends on the probability of the relative parameters. \n",
    "\n",
    "According to the law of total probabilities we have:\n",
    "\n",
    "$$ p(X|M) = \\int_\\boldsymbol{\\theta} p(X|\\boldsymbol{\\theta}, M) p(\\boldsymbol{\\theta}|M) d\\boldsymbol{\\theta} $$\n",
    "\n",
    "The model evidence is sometimes also called the marginal likelihood because it can be viewed as a likelihood function over the space of models, in which the parameters have been integrated (marginalized) out. Correctly evaluating this integral allows us to  marginalize (or sum or integrate) over the model parameters instead of making point estimates of their values. This naturally allows us to compensate for over-fitting associated with maximum likelihood.\n",
    "\n",
    "From a sampling perspective, the marginal likelihood can be viewed as the probability of generating the data set X from a model whose parameters $\\boldsymbol{\\theta}$ are sampled at random from the prior $p(\\boldsymbol{\\theta}|M)$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a random variable that produces either a success or a failure. We want to compare a model M1 where the probability of success is q = 0.5, and another model M2 where q is unknown and we take a prior distribution for q that is uniform on [0,1]. We take a sample of 200, and find 115 successes and 85 failures. \n",
    "\n",
    "The evidence for model $M_1$ will be:\n",
    "\n",
    "$$ p(X|M_1) = p(X|q=0.5) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:  p( q=0.5) = 1\n",
      "p(X = 115 | M1) = 0.00595589219024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "N_trials  = 200\n",
    "N_success = 115\n",
    "\n",
    "## Model 1:  p(q=0.5) = 1\n",
    "q = 0.5\n",
    "evidence_M1 = binom.pmf(N_success,N_trials,q)\n",
    "\n",
    "print('Model 1:  p( q={}) = 1'.format(q))\n",
    "print('p(X = {} | M1) = {}'.format(N_success, evidence_M1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model $M_2$ we need to compute the integral over all the possible sets of parameters' values $q$.\n",
    "\n",
    "The evidence for model $M_2$ will be:\n",
    "\n",
    "\\begin{align*} \n",
    "p(X|M_2) &= \\int p(X|q,M_2) p(q|M_2)dq = \\int p(X|q,M_2) dq \\\\\n",
    " &= {200 \\choose 115} \\int q^{115}(1-q)^{85}dq\\\\\n",
    " &= {200 \\choose 115} B(116,86) = {200 \\choose 115} \\frac{115! 85!}{(115+85-1)!} = \\frac{1}{201}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2:  p( q) = U(0,1)\n",
      "p(X = 115  | M2) = 0.00497512437811\n",
      "Alternative computation based on Monte Carlo sampling\n",
      "p(X = 115  | M2) = 0.0046455523538\n"
     ]
    }
   ],
   "source": [
    "print('Model 2:  p( q) = U(0,1)')\n",
    "\n",
    "evidence_M2 = 1./201\n",
    "\n",
    "print('p(X = 115  | M2) = {}'.format(evidence_M2))\n",
    "\n",
    "\n",
    "## Alternative approach based on sampling\n",
    "from scipy.special import binom\n",
    "q = np.random.rand(1000)\n",
    "integral = np.mean(np.exp(115*np.log(q) + 85*np.log(1-q))) \n",
    "\n",
    "evidence_M2 = integral * binom(200,115)\n",
    "print('Alternative computation based on Monte Carlo sampling')\n",
    "print('p(X = 115  | M2) = {}'.format(evidence_M2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bayes factor is: 1.19713433024\n"
     ]
    }
   ],
   "source": [
    "print('The Bayes factor is: ' + str(evidence_M1/evidence_M2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes factor therefore is slightly indicative of a larger evidence for $M_1$. Indeed, $M_2$ is a more complex model than M1 because it has a free parameter which allows it to model the data more closely. The ability of Bayes factors to take this into account is a reason why Bayesian inference has been put forward as a theoretical justification for and generalisation of Occam's razor.\n",
    "\n",
    "The maximum likelihood estimate for the parameter $q$ under the model $M_2$ would be $q = 115/200 = 0.575$.\n",
    "Using this parameter estimate we obtain a likelihood of $p(X|q=0.575) = {200 \\choose 115} q^{115}(1-q)^{85} = 0.056991$. \n",
    "\n",
    "We can then use the AIC for comparing the two models. Under $M_1$ we have 0 parameters as we fixed $q$ from the beginning, and the AIC will be:\n",
    "\n",
    "$$ AIC_{M_1} = -2 D_{M_1} + 2 N_{parameters} = − 2·ln(0.005956) + 2·0 = 10.2467 $$\n",
    "\n",
    "Under model $M_2$ we have 1 free parameter $q\\in [0,1]$, whose maximum likelihood estimation is $q = 0.575$.\n",
    "The AIC will be:\n",
    "\n",
    "$$ AIC_{M_2} = -2 D_{M_2} + 2 N_{parameters} = − 2·ln(0.056991) + 2·1 = 7.7297. $$\n",
    "\n",
    "We observe that, although the likeihood of $M_2$ is about 1- times larger than for $M_1$, the AIC only slightly favour $M_2$. This is because of the penalization over the complexity of $M_2$. If we compute the Akaike weights we obtain:\n",
    "\n",
    "$$w = exp(-(10.2467-7.7297)/2) = 0.284$$\n",
    "\n",
    "\n",
    "Thus $M_2$ is 0.28 more probable than $M_1$, which means that we cannot exclude $M_1$ on the basis of this experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.__ Given the following data, estimate by repeated cross-validation the prediction accuracy of the classifciation algorithms: Logistic Regression, Decision Tree, and K-Nearest Neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "dataframe[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.__ Compute a 95% confidence interval for the difference between the prediction accuracy of Logistic Regression and K-Nearest Neighborhoods. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.__ Compute the probability of the average prediction of K-Nearest Neighborhoods being greater than 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
